{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Gemini Becomes an Expert\n\nThe idea builds on Google's Gemini LLM to offer detailed responses on specialized topics. It addresses the limitations of language models, such as their tendency to miss nuanced details or very specific formulas where accuracy is critical, and their potential for generating incorrect information or \"hallucinations.\" By converting user queries into targeted searches across multiple platforms—Wikipedia for foundational concepts, the web for in-depth technical details, YouTube for explanatory and comparative content, and Arxiv for scholarly articles—the algorithm ensures a thorough collection of information. A web scraping component then aggregates this data into a vast text file, often exceeding a million characters. This method provides a robust foundation of context, functioning as a solution to enhance the accuracy and depth of the responses generated by the LLM, mimicking the comprehensive research typically conducted by human experts.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# Install all the necessary libraries\n!pip install google-generativeai\n!pip install arxiv2text\n!pip install arxiv\n!pip install googlesearch-python\n!pip install beautifulsoup4\n!pip install youtube-transcript-api","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:22:38.022433Z","iopub.execute_input":"2024-10-21T11:22:38.023000Z","iopub.status.idle":"2024-10-21T11:24:12.097665Z","shell.execute_reply.started":"2024-10-21T11:22:38.022952Z","shell.execute_reply":"2024-10-21T11:24:12.096096Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /opt/conda/lib/python3.10/site-packages (0.8.2)\nRequirement already satisfied: google-ai-generativelanguage==0.6.10 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (0.6.10)\nRequirement already satisfied: google-api-core in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.11.1)\nRequirement already satisfied: google-api-python-client in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.147.0)\nRequirement already satisfied: google-auth>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.30.0)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (2.9.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.66.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from google-generativeai) (4.12.2)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/conda/lib/python3.10/site-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.23.0)\nRequirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (1.63.1)\nRequirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core->google-generativeai) (2.32.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\nRequirement already satisfied: httplib2<1.dev0,>=0.19.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.21.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from google-api-python-client->google-generativeai) (3.0.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic->google-generativeai) (2.23.4)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.64.1)\nRequirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.48.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\nCollecting arxiv2text\n  Downloading arxiv2text-0.1.14-py3-none-any.whl.metadata (4.4 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from arxiv2text) (4.12.3)\nCollecting pdfminer-six (from arxiv2text)\n  Downloading pdfminer.six-20240706-py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from arxiv2text) (1.2.2)\nCollecting PyPDF2 (from arxiv2text)\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->arxiv2text) (2.5)\nRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer-six->arxiv2text) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer-six->arxiv2text) (42.0.8)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->arxiv2text) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->arxiv2text) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->arxiv2text) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->arxiv2text) (3.5.0)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer-six->arxiv2text) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer-six->arxiv2text) (2.22)\nDownloading arxiv2text-0.1.14-py3-none-any.whl (15 kB)\nDownloading pdfminer.six-20240706-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2, pdfminer-six, arxiv2text\nSuccessfully installed PyPDF2-3.0.1 arxiv2text-0.1.14 pdfminer-six-20240706\nCollecting arxiv\n  Downloading arxiv-2.1.3-py3-none-any.whl.metadata (6.1 kB)\nCollecting feedparser~=6.0.10 (from arxiv)\n  Downloading feedparser-6.0.11-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: requests~=2.32.0 in /opt/conda/lib/python3.10/site-packages (from arxiv) (2.32.3)\nCollecting sgmllib3k (from feedparser~=6.0.10->arxiv)\n  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.32.0->arxiv) (2024.8.30)\nDownloading arxiv-2.1.3-py3-none-any.whl (11 kB)\nDownloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: sgmllib3k\n  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6049 sha256=a770a9ba91f5441413f41f3fdc8caa926aafa4ea4025719e7554b83289dbbf73\n  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\nSuccessfully built sgmllib3k\nInstalling collected packages: sgmllib3k, feedparser, arxiv\nSuccessfully installed arxiv-2.1.3 feedparser-6.0.11 sgmllib3k-1.0.0\nCollecting googlesearch-python\n  Downloading googlesearch_python-1.2.5-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: beautifulsoup4>=4.9 in /opt/conda/lib/python3.10/site-packages (from googlesearch-python) (4.12.3)\nRequirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.10/site-packages (from googlesearch-python) (2.32.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->googlesearch-python) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->googlesearch-python) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->googlesearch-python) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.20->googlesearch-python) (2024.8.30)\nDownloading googlesearch_python-1.2.5-py3-none-any.whl (4.8 kB)\nInstalling collected packages: googlesearch-python\nSuccessfully installed googlesearch-python-1.2.5\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.12.3)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.5)\nCollecting youtube-transcript-api\n  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from youtube-transcript-api) (2.32.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->youtube-transcript-api) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->youtube-transcript-api) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->youtube-transcript-api) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->youtube-transcript-api) (2024.8.30)\nDownloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\nInstalling collected packages: youtube-transcript-api\nSuccessfully installed youtube-transcript-api-0.6.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import all the libraries we will need\n# Standard library imports\nimport datetime\nimport json\nimport re\nimport time\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\n\n# Related third-party imports\nimport arxiv\nimport requests\nfrom arxiv2text import arxiv_to_text\nfrom bs4 import BeautifulSoup\nfrom googlesearch import search\nfrom tqdm import tqdm\nfrom youtube_transcript_api import YouTubeTranscriptApi\n\n# Imports from the google.generativeai library\nimport google.generativeai as genai\nfrom google.generativeai import caching\nfrom google.generativeai.types import GenerationConfig\n\n# Initialize the arxiv client\nclient = arxiv.Client()","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:51:31.793831Z","iopub.execute_input":"2024-10-21T11:51:31.794437Z","iopub.status.idle":"2024-10-21T11:51:31.804712Z","shell.execute_reply.started":"2024-10-21T11:51:31.794388Z","shell.execute_reply":"2024-10-21T11:51:31.802770Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# Use Kaggle secrets to store and retrieve your Gemini API Key\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\napi_key = user_secrets.get_secret(\"API_KEY\")\n# Set it!\ngenai.configure(api_key=api_key)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:33:54.034540Z","iopub.execute_input":"2024-10-21T11:33:54.035049Z","iopub.status.idle":"2024-10-21T11:33:54.249582Z","shell.execute_reply.started":"2024-10-21T11:33:54.035005Z","shell.execute_reply":"2024-10-21T11:33:54.248009Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"user_query = \"I want to understand the diffusion implicit model (DDIM). More exactly, how is it deterministic if the counterpart works in stochasticly.\"","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:28:41.878275Z","iopub.execute_input":"2024-10-21T11:28:41.879128Z","iopub.status.idle":"2024-10-21T11:28:41.885405Z","shell.execute_reply.started":"2024-10-21T11:28:41.879069Z","shell.execute_reply":"2024-10-21T11:28:41.883952Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Extract Online Knowledge","metadata":{}},{"cell_type":"markdown","source":"### Use an Agent to Create Queries","metadata":{}},{"cell_type":"code","source":"google_searcher_agent_instructions = \"\"\"You are a google searcher agent. From a given user query, your job is to create a series of google search queries (from general to specific) so you can become an expert in the matter before answering.\nDo not literally copy the user's query, instead, be intelligent about it and use your own knowledge in the matter to create a list of queries that the user might find best helpful.\nYou will respond only in JSON format. Answer only with queries (from general to specific) split by the sites: web, wikipedia, arxiv and youtube, WITHOUT OEVERLAPPING!.  Fill them however you want, but do not write too many queries (at most 4).\nDO NOT ANSWER THE USER QUERY! THAT IS NOT YOUR TASK!\nExamples:\n\n# EXAMPLE 1\n## USER INPUT\nUser query: \"I want to learn more about generative AI models, specifically diffusion models, and how they compare to GANs.\"\n## YOUR OUTPUT\n{\n    \"wikipedia\": [\"Generative AI\"],\n    \"web\": [\"How autorregresive denoising diffusion models work\"],\n    \"youtube\": [\"Diffusion models explained\", \"GANs vs Diffusion models comparison\"],\n    \"arxiv\": [\"Normalizing Flows\", \"Variational Autoencoders\", \"Generative Adversarial Network\", \"Autorregresive Denoising Probabilistic Models\"]\n}\n\n# EXAMPLE 2\n## USER INPUT\nUser query: \"Puedes escribir un articulo sobre manolo valdes (el escultor)? Biografia, sus obras, etc\"\n## YOUR OUTPUT\n{\n    \"wikipedia\": [\"Manolo Valdés\", \"Spanish sculptors\", \"Pop Art in Spain\"],\n    \"web\": [\"Manolo Valdés biography\", \"Manolo Valdés famous sculptures\", \"Analysis of Manolo Valdés artworks\"],\n    \"youtube\": [],\n    \"arxiv\": []\n}\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:29:30.656841Z","iopub.execute_input":"2024-10-21T11:29:30.657380Z","iopub.status.idle":"2024-10-21T11:29:30.666025Z","shell.execute_reply.started":"2024-10-21T11:29:30.657332Z","shell.execute_reply":"2024-10-21T11:29:30.664472Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# We call out first agent\ngoogle_searcher_agent = genai.GenerativeModel(\n    \"gemini-1.5-flash-002\",\n    system_instruction=google_searcher_agent_instructions,\n    generation_config={\"response_mime_type\": \"application/json\"}\n)\nresponse = google_searcher_agent.generate_content(\"User query: \" + user_query)\ngoogle_queries = json.loads(response.text)\ngoogle_queries","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:34:01.123001Z","iopub.execute_input":"2024-10-21T11:34:01.123485Z","iopub.status.idle":"2024-10-21T11:34:02.026363Z","shell.execute_reply.started":"2024-10-21T11:34:01.123439Z","shell.execute_reply":"2024-10-21T11:34:02.024744Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'wikipedia': ['Diffusion models', 'Markov chains'],\n 'web': ['DDIM algorithm explained',\n  'Deterministic diffusion models',\n  'Comparison of DDIM and DDPM'],\n 'youtube': ['DDIM tutorial', 'Understanding diffusion models'],\n 'arxiv': ['Denoising Diffusion Probabilistic Models',\n  'Improved Denoising Diffusion Probabilistic Models']}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Extract information from resources","metadata":{}},{"cell_type":"code","source":"# We create all necessary functions to get the context from the internet\n\ndef google_search(query, num_results):\n    # Use google-search-api to get the top-n best results\n    query = f\"{query}\"\n    result = search(query, num_results=num_results)\n    return result\n\n\ndef extract_and_format_text_from_url(url):\n    # Extract all readable text from a website\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n    except requests.RequestException as e:\n        return f\"Failed to retrieve content: {e}\"\n    soup = BeautifulSoup(response.text, 'html.parser')\n    tags_of_interest = {f\"h{i}\": \"#\" * i for i in range(1, 7)}\n    tags_of_interest[\"p\"] = ''\n    formatted_text_segments = []\n    for element in soup.descendants:\n        if element.name in tags_of_interest:\n            prefix = tags_of_interest[element.name]\n            text = element.get_text(strip=True)\n            if text:\n                if prefix:\n                    formatted_text_segments.append(f\"{prefix} {text}\\n\")\n                else:\n                    formatted_text_segments.append(f\"{text}\\n\")\n    formatted_text = '\\n'.join(formatted_text_segments)\n    return formatted_text\n\n\ndef process_link(site_query, link, result_type, i, num_links):\n    # Processes general website\n    if result_type == 'web' and any(sub in link for sub in [\"insta\", \"youtube\", \"wiki\"]):\n        return None\n    try:\n        web_text = extract_and_format_text_from_url(link)\n    except Exception as e:\n        print(f\"Error processing link {link}: {e}\")\n        return None\n    header = f\"\"\"\n    -------------------------\n    QUERY: {site_query}\n    {result_type.upper()} RESULTS {i + 1}/{num_links}\n    URL: {link}\n    -------------------------\n\n    \"\"\"\n    return header + web_text\n\n\ndef process_web_query(site_query, num_results=10):\n    # Processes web query in parallel\n    links = list(google_search(site_query, num_results))\n    num_links = len(links)\n    results = []\n    with ThreadPoolExecutor(max_workers=5) as executor:\n        futures = [\n            executor.submit(process_link, site_query, link, 'web', i, num_links)\n            for i, link in enumerate(links)\n        ]\n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                results.append(result)\n    return \"\\n\\n\".join(results)\n\n\ndef process_wikipedia_query(site_query, num_results=2):\n    # Processes wikipedia query in parallel\n    links = list(google_search(f\"{site_query} site:wikipedia.org\", num_results))\n    num_links = len(links)\n    results = []\n    with ThreadPoolExecutor(max_workers=5) as executor:\n        futures = [\n            executor.submit(process_link, site_query, link, 'wikipedia', i, num_links)\n            for i, link in enumerate(links)\n        ]\n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                results.append(result)\n    return \"\\n\\n\".join(results)\n\n\ndef process_arxiv_query(arxiv_query, num_results=5):\n    # Processes Arxiv query in parallel\n    arxiv_search = arxiv.Search(\n        query=arxiv_query,\n        max_results=num_results,\n        sort_by=arxiv.SortCriterion.Relevance\n    )\n    result_urls = list(client.results(arxiv_search))\n    num_results = len(result_urls)\n    results = []\n\n    def process_arxiv_result(i, result_url):\n        try:\n            result_pdf_url = result_url.pdf_url.replace(\"/abs/\", \"/pdf/\")\n            extracted_text = arxiv_to_text(result_pdf_url)\n            header = f\"\"\"\n            -------------------------\n            QUERY: {arxiv_query}\n            ARXIV RESULTS {i + 1}/{num_results}\n            URL: {result_url}\n            -------------------------\n\n            \"\"\"\n            return header + extracted_text\n        except Exception as e:\n            print(\"Error with arXiv...\", e)\n            return None\n\n    with ThreadPoolExecutor(max_workers=5) as executor:\n        futures = [\n            executor.submit(process_arxiv_result, i, result_url)\n            for i, result_url in enumerate(result_urls)\n        ]\n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                results.append(result)\n    return \"\\n\\n\".join(results)\n\n\ndef process_youtube_query(site_query, num_results=5):\n    # Processes YouTube query in parallel\n    links = list(google_search(f\"{site_query} site:youtube.com\", num_results))\n    num_links = len(links)\n    results = []\n\n    def process_youtube_link(i, link):\n        try:\n            if \"https://www.youtube.com/watch?v=\" not in link:\n                return None\n            youtube_id = link.split(\"v=\")[-1].split(\"&\")[0]\n            transcripts = YouTubeTranscriptApi.list_transcripts(youtube_id)\n            transcript = transcripts.find_transcript(['en', 'en-US', 'en-GB'])\n            video_transcription = transcript.fetch()\n            video_transcription = \" \".join([r[\"text\"] for r in video_transcription])\n            header = f\"\"\"\n            -------------------------\n            QUERY: {site_query}\n            YOUTUBE RESULTS {i + 1}/{num_links}\n            URL: {link}\n            (this is a transcription, text might have errors)\n            -------------------------\n\n            \"\"\"\n            return header + video_transcription\n        except Exception as e:\n            print(\"Error with YouTube...\", e)\n            return None\n\n    with ThreadPoolExecutor(max_workers=5) as executor:\n        futures = [\n            executor.submit(process_youtube_link, i, link)\n            for i, link in enumerate(links)\n        ]\n        for future in as_completed(futures):\n            result = future.result()\n            if result:\n                results.append(result)\n    return \"\\n\\n\".join(results)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:41:12.410885Z","iopub.execute_input":"2024-10-21T11:41:12.411361Z","iopub.status.idle":"2024-10-21T11:41:12.447104Z","shell.execute_reply.started":"2024-10-21T11:41:12.411314Z","shell.execute_reply":"2024-10-21T11:41:12.445331Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Execute search! Typically takes like ~45sec (thanks to parallelization!)\n\nexpert_context_parts = []\ntasks = []\n\n# Prepare tasks for all query types\nfor site_query in google_queries.get(\"web\", []):\n    tasks.append(('Web', process_web_query, site_query))\n\nfor site_query in google_queries.get(\"web\", []):\n    tasks.append(('Wikipedia', process_wikipedia_query, site_query))\n\nfor arxiv_query in google_queries.get(\"arxiv\", []):\n    tasks.append(('ArXiv', process_arxiv_query, arxiv_query))\n\nfor site_query in google_queries.get(\"youtube\", []):\n    tasks.append(('YouTube', process_youtube_query, site_query))\n\n# Run all tasks in parallel\nprint(\"Starting all searches in parallel...\")\nwith ThreadPoolExecutor(max_workers=20) as executor:\n    futures = {\n        executor.submit(func, query): (source, query)\n        for source, func, query in tasks\n    }\n    for future in tqdm.tqdm(as_completed(futures), total=len(futures)):\n        source, query = futures[future]\n        try:\n            result = future.result()\n            if result:\n                expert_context_parts.append(result)\n        except Exception as e:\n            print(f\"Error processing {source} query '{query}': {e}\")\n\nexpert_context = \"\\n\\n\".join(expert_context_parts)\n\n# Save to file\nprint(\"Saving context file...\")\npath_to_context_file = 'expert_context.txt'\nwith open(path_to_context_file, \"w\", encoding=\"utf-8\") as file:\n    file.write(expert_context)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:41:48.049440Z","iopub.execute_input":"2024-10-21T11:41:48.049964Z","iopub.status.idle":"2024-10-21T11:42:36.223073Z","shell.execute_reply.started":"2024-10-21T11:41:48.049914Z","shell.execute_reply":"2024-10-21T11:42:36.221620Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Starting all searches in parallel...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 10/10 [00:48<00:00,  4.81s/it]","output_type":"stream"},{"name":"stdout","text":"Saving context file...\nDone!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Length reference\nnum_words = len(expert_context.split(\" \"))\nharry_potter_sorcerers_stone_num_words = 76_944\nprint(f\"Your expert context is {(num_words / harry_potter_sorcerers_stone_num_words):.2f} Harry Potter's (and the sorcerer's stone) book(s)!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:49:56.804634Z","iopub.execute_input":"2024-10-21T11:49:56.805142Z","iopub.status.idle":"2024-10-21T11:49:56.825562Z","shell.execute_reply.started":"2024-10-21T11:49:56.805094Z","shell.execute_reply":"2024-10-21T11:49:56.823812Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Your expert context is 1.27 Harry Potter's (and the sorcerer's stone) book(s)!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Use the TXT as Context for the LLM","metadata":{}},{"cell_type":"code","source":"# Cache model system instruction with an small Chain of Thought added\nsystem_instruction = \"\"\"You are an agent with the task of resolving a user's questions and tasks in the most helpful way possible. The user will be talking about some topic, asking questions and everything.\nYou will be given a related huge context that is the result of an intensive web scrapping about the asked topic, use this context as reference and as help to answer the user's questions.\nRules:\n- As every section has an URL, YOU MUST PROVIDE SOURCES FOR EVERY CLAIM YOU WRITE IN THE OUTPUT!\n- No matter the context language, answer in the user's request language.\n- Use Chain of Thought reasoning before answering. Before answering the user's request, write a <thinking> token with internal thoughts of how could you use the full given context in a way that helps the user in the best possible and unique way, using the huge provided context parts that the user might find best helpful. Whenever you finish thinking, write a </thinking> token and start answering normally. The user won't see whatever you write between your <thinking> and </thinking> tokens, just the answer.\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:58:44.890442Z","iopub.execute_input":"2024-10-21T11:58:44.891017Z","iopub.status.idle":"2024-10-21T11:58:44.898910Z","shell.execute_reply.started":"2024-10-21T11:58:44.890968Z","shell.execute_reply":"2024-10-21T11:58:44.897327Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Use the cache functionality in Gemini to store the context for further queries\npath_to_context_file = 'expert_context.txt'\ncontext_file = genai.upload_file(path=path_to_context_file)\n\nwhile context_file.state.name == 'PROCESSING':\n    print('Waiting for context to be processed.')\n    time.sleep(2)\n    video_file = genai.get_file(context_file.name)\nprint(f'Context processing complete: {context_file.uri}')\n\ncache = caching.CachedContent.create(\n    model='gemini-1.5-pro-002',\n    display_name='context',\n    system_instruction=system_instruction,\n    contents=[context_file],\n    ttl=datetime.timedelta(minutes=3)\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:59:10.733481Z","iopub.execute_input":"2024-10-21T11:59:10.734581Z","iopub.status.idle":"2024-10-21T11:59:13.795892Z","shell.execute_reply.started":"2024-10-21T11:59:10.734523Z","shell.execute_reply":"2024-10-21T11:59:13.794174Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Context processing complete: https://generativelanguage.googleapis.com/v1beta/files/zkmf10fkt34j\n","output_type":"stream"}]},{"cell_type":"code","source":"def remove_thinking_tags_precise(text):\n    # Remove thinking tokens from Chain of Thought\n    return re.sub(r'<thinking>.*?</thinking>', '', text, flags=re.DOTALL)\n\n\n# We can create a model from this cache and start a chat\n# High tokens output and low temperature to ensure low hallucinations and complete explanations\nconfig = GenerationConfig(max_output_tokens=int(2**13), temperature=0.3)\nmodel = genai.GenerativeModel.from_cached_content(\n    cached_content=cache,\n    generation_config=config\n)\nchat = model.start_chat()","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:59:28.296146Z","iopub.execute_input":"2024-10-21T11:59:28.296686Z","iopub.status.idle":"2024-10-21T11:59:28.305372Z","shell.execute_reply.started":"2024-10-21T11:59:28.296642Z","shell.execute_reply":"2024-10-21T11:59:28.303845Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Send the original message\nresponse = chat.send_message(user_query)\nanswer = remove_thinking_tags_precise(response.text)\nprint(answer)","metadata":{"execution":{"iopub.status.busy":"2024-10-21T11:59:33.371640Z","iopub.execute_input":"2024-10-21T11:59:33.372092Z","iopub.status.idle":"2024-10-21T12:00:01.369578Z","shell.execute_reply.started":"2024-10-21T11:59:33.372051Z","shell.execute_reply":"2024-10-21T12:00:01.367863Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"\nDDIM is deterministic because it removes the stochastic element present in DDPM's sampling process.  Let's break down the key difference:\n\nIn DDPM (Denoising Diffusion Probabilistic Models), the reverse diffusion (sampling) process involves iteratively removing noise from a pure noise image to generate a sample. This process is *stochastic* because at each step, it adds random Gaussian noise.  This means that even with the same starting noise and the same model, DDPM can produce different final images due to the randomness injected at each step.\n\nDDIM (Denoising Diffusion Implicit Models), on the other hand, modifies the sampling process to be *deterministic*.  It achieves this by eliminating the addition of random noise during the reverse diffusion process.  The equation for generating a sample `x_(t-1)` from `x_t` in DDIM is ([https://john-see.github.io/blog/2020/DDIM/](https://john-see.github.io/blog/2020/DDIM/)):\n\n```\nx_(t-1) = sqrt(α_t) * x_0 + sqrt(1-α_t-σ_t^2) * ε_θ(x_t) + σ_t * ε_t\n```\n\nwhere `ε_t ~ N(0, I)` is the random noise term.  DDIM sets `σ_t = 0` for all `t`, effectively removing this random noise.  This makes the sampling process entirely deterministic: given a starting noise image `x_T`, DDIM will always produce the same output `x_0`.\n\nIn essence, both DDIM and DDPM are trained using the same principle of learning to reverse a diffusion process. However, they differ in how they apply this learned knowledge during sampling. DDPM uses a stochastic sampling process, while DDIM employs a deterministic one by removing the random noise component.  This key difference allows DDIM to generate consistent outputs for a given input noise, while still benefiting from the training process of DDPM. Also, as explained in the HuggingFace documentation ([https://huggingface.co/docs/diffusers/v0.11.0/en/api/schedulers/ddim](https://huggingface.co/docs/diffusers/v0.11.0/en/api/schedulers/ddim)), DDIM allows for \"trading off computation for sample quality\" and performing \"semantically meaningful image interpolation directly in the latent space,\" which are not possible with DDPM's stochastic nature.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Keep chatting!\n\n# Keep the conversation alive!\ncache.update(ttl=datetime.timedelta(minutes=3))\n\n# Send the next question (related to the same context)\nuser_query = \"Add your message here!\"\nresponse = chat.send_message(user_query)\nanswer = remove_thinking_tags_precise(response.text)\nprint(answer)","metadata":{},"execution_count":null,"outputs":[]}]}