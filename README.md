# Gemini-Becomes-an-Expert
By converting user queries into targeted searches across multiple platforms the algorithm ensures a thorough collection of information.

This is the code for the Kaggle competition: [https://www.kaggle.com/competitions/gemini-long-context](https://www.kaggle.com/competitions/gemini-long-context)

Unfortunately, I couldn't submit this since I already submitted one idea already [https://github.com/diegobonilla98/Gemini-Video-Highlights](https://github.com/diegobonilla98/Gemini-Video-Highlights).


## Summary
The idea builds on Google's Gemini LLM to offer detailed responses on specialized topics. It addresses the limitations of language models, such as their tendency to miss nuanced details or very specific formulas where accuracy is critical, or their lack of online knowledge, and their potential for generating incorrect information or "hallucinations." By converting user queries into targeted searches across multiple platforms—Wikipedia for foundational concepts, the web for in-depth technical details, YouTube for explanatory and comparative content, and Arxiv for scholarly articles—the algorithm ensures a thorough collection of information. A web scraping component then aggregates this data into a vast text file, often exceeding a million characters. This method provides a robust foundation of context, functioning as a solution to enhance the accuracy and depth of the responses generated by the LLM, mimicking the comprehensive research typically conducted by human experts.
When generating new text, there is a very naive implementation of "thinking before answering" to use the source material in the answer and provide sources.

![](./gemini_becomes_an_expert.png)
